from __future__ import annotations
import os, re, json, traceback
from pathlib import Path
import streamlit as st

from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain.retrievers import EnsembleRetriever

# ----- ë°°ê²½ ì´ë¯¸ì§€ í—¬í¼: ì•± ë§¨ ìœ„ì— ì¶”ê°€ -----
import base64, os
from pathlib import Path
import streamlit as st

@st.cache_data
def _b64_img(path: str) -> str:
    return base64.b64encode(Path(path).read_bytes()).decode()

def set_background(image_path: str | None = None,
                   image_url: str | None = None,
                   opacity: float = 0.18,   # ì–´ë‘¡ê²Œ ì˜¤ë²„ë ˆì´
                   blur_px: int = 0):       # ì‚¬ì´ë“œë°” ë¸”ëŸ¬
    if image_path:
        ext = Path(image_path).suffix[1:] or "png"
        src = f"data:image/{ext};base64,{_b64_img(image_path)}"
    elif image_url:
        src = image_url
    else:
        return

    st.markdown(f"""
    <style>
    /* ì „ì²´ ì•± ë°°ê²½ */
    .stApp {{
        background: linear-gradient(rgba(0,0,0,{opacity}), rgba(0,0,0,{opacity})),
                    url('{src}') no-repeat center center fixed;
        background-size: cover;
    }}
    /* ì‚¬ì´ë“œë°” ì‚´ì§ ë°˜íˆ¬ëª…/ë¸”ëŸ¬ (ì„ íƒ) */
    section[data-testid="stSidebar"] > div:first-child {{
        background: rgba(0,0,0,0.25);
        backdrop-filter: blur({blur_px}px);
    }}
    </style>
    """, unsafe_allow_html=True)


# ====== ê²½ë¡œ/ëª¨ë¸ ì„¤ì • ======
INDEX_DIR    = "./artifacts/faiss_index"
NAMES_PATH   = "./artifacts/player_names.json"   # build_docs.pyê°€ ìƒì„±
EMB_MODEL    = "intfloat/multilingual-e5-base"   # ë˜ëŠ” "BAAI/bge-m3", "paraphrase-multilingual-MiniLM-L12-v2"
OLLAMA_MODEL = "gemma3:4b"                       # ë¡œì»¬ì— ì¡´ì¬í•˜ëŠ” ëª¨ë¸ëª…ìœ¼ë¡œ

# ====== ìœ í‹¸ ======
def needs_query_prefix(model_name: str) -> bool:
    name = model_name.lower()
    return ("e5" in name) or ("bge" in name)

QUERY_PREFIX = "query: " if needs_query_prefix(EMB_MODEL) else ""

STATS_KEYWORDS = r"(ì„±ì |ê¸°ë¡|ìŠ¤íƒ¯|íƒ€ìœ¨|ì¶œë£¨ìœ¨|ì¥íƒ€ìœ¨|ops|war|wrc\+|woba|era|fip|whip|ì´ë‹|ì„¸ì´ë¸Œ|í™€ë“œ|í†µì‚°|ì‹œì¦Œ|ìˆ˜ì¹˜|ì •ëŸ‰|streak|í‰ê· |ì§€í‘œ)"

@st.cache_data
def load_player_names() -> list[str]:
    # build_docs.pyì—ì„œ ë§Œë“  ì´ë¦„ ëª©ë¡ ìš°ì„  ì‚¬ìš©
    if Path(NAMES_PATH).exists():
        with open(NAMES_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    # ë°±ì—…: CSVì—ì„œ ì§ì ‘ ë¡œë“œ(íŒŒì¼ ê²½ë¡œ í•„ìš” ì‹œ ìˆ˜ì •)
    names = set()
    try:
        import pandas as pd
        for p in ["./2025csv/hitter_basic_all.csv", "./2025csv/pitcher_basic_all.csv"]:
            if Path(p).exists():
                df = pd.read_csv(p, encoding="utf-8", low_memory=False)
                if "ì„ ìˆ˜ëª…" in df.columns:
                    names.update(df["ì„ ìˆ˜ëª…"].dropna().astype(str).str.strip())
    except Exception:
        pass
    return sorted(names)

PLAYER_NAMES = load_player_names()

def normalize_ko(s: str) -> str:
    return re.sub(r"\s+", "", s)

def extract_name(query: str) -> str | None:
    q = normalize_ko(query)
    # 1) ì™„ì „/ë¶€ë¶„ í¬í•¨ (ê°€ì¥ ê¸´ ì´ë¦„ ìš°ì„ )
    cands = [n for n in PLAYER_NAMES if normalize_ko(n) in q]
    if cands:
        return max(cands, key=len)
    # 2) í¼ì§€ ë§¤ì¹­(ì„ íƒ)
    try:
        from rapidfuzz import process, fuzz
        name, score, _ = process.extractOne(q, PLAYER_NAMES, scorer=fuzz.WRatio)
        if score >= 90:
            return name
    except Exception:
        pass
    return None

def is_stats_query(q: str) -> bool:
    return re.search(STATS_KEYWORDS, q, flags=re.IGNORECASE) is not None

# ====== ë¦¬ì†ŒìŠ¤ ======
# 1) ë²¡í„°ìŠ¤í† ì–´ë§Œ ìºì‹œ (retrieverëŠ” ë§¤ ì§ˆë¬¸ë§ˆë‹¤ ìƒì„±)
@st.cache_resource
def get_vectorstore():
    embeddings = HuggingFaceEmbeddings(
        model_name=EMB_MODEL,
        model_kwargs={"device": "mps"},
        encode_kwargs={"normalize_embeddings": True, "batch_size": 256}
    )
    vs = FAISS.load_local(INDEX_DIR, embeddings, allow_dangerous_deserialization=True)
    return vs

def make_retrievers(vs, filter_dict: dict | None, stats_intent: bool):
    # ê³µí†µ MMR ì„¤ì •
    mmr_kwargs = {"k": 8, "fetch_k": 40, "lambda_mult": 0.3}

    if stats_intent:
        # ì •ëŸ‰ ì˜ë„ -> statsë§Œ
        filt = {"type": "stats", **(filter_dict or {})}
        retriever = vs.as_retriever(search_type="mmr", search_kwargs={**mmr_kwargs, "filter": filt})
        return retriever

    # ì •ì„±(ê¸°ë³¸) -> ìœ„í‚¤ ê°€ì¤‘ ì•™ìƒë¸”
    wiki_filt = {"type": "wiki", **(filter_dict or {})} if filter_dict else {"type": "wiki"}
    base_filt = filter_dict or {}

    wiki_ret = vs.as_retriever(search_type="mmr", search_kwargs={**mmr_kwargs, "filter": wiki_filt})
    base_ret = vs.as_retriever(search_type="mmr", search_kwargs={**mmr_kwargs, "filter": base_filt} if base_filt else mmr_kwargs)

    from langchain.retrievers import EnsembleRetriever
    return EnsembleRetriever(retrievers=[wiki_ret, base_ret], weights=[0.7, 0.3])

@st.cache_resource
def get_llm():
    llm = ChatOllama(model=OLLAMA_MODEL)
    _ = llm.invoke("ping")  # í—¬ìŠ¤ì²´í¬
    return llm

@st.cache_resource
def get_prompt():
    return ChatPromptTemplate.from_template(
        "ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•´ í•œêµ­ì–´ë¡œ ì •í™•íˆ ë‹µí•˜ë¼.\n"
        "ì˜ˆë¥¼ ë“¤ì–´, SSG ìµœì •ì˜ ë³„ëª…ì„ ë¬¼ìœ¼ë©´, ì •ë‹µì€ ë§ˆê·¸ë„·ì •, ì†Œë…„ì¥ì‚¬ì•¼. ì´ì²˜ëŸ¼ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•´ë¼.\n"
        "íŠ¹íˆ ì„ ìˆ˜ì˜ ì´ë¦„ì€ ì¤‘ìš”í•œ ì •ë³´ì´ë‹ˆ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì£¼ì–´ì§€ë©´ ê¼­ í™œìš©í•´ë¼.\n"
        "ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´ë¼.\n\n<context>\n{context}\n</context>\n\nì§ˆë¬¸: {input}"
    )

# ====== ì•± ======
st.title("âš¾ï¸ 2025 KBO RAG")
st.markdown("ì‚¬ì „ êµ¬ì¶•í•œ ì¸ë±ìŠ¤ë¥¼ ì´ìš©í•´ 2025 ì‹œì¦Œ ì„ ìˆ˜ ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤.")

st.set_page_config(page_title="KBO RAG", layout="wide")
set_background(image_path="logo2.jpg", opacity=0.22, blur_px=6)   # ë˜ëŠ” image_url="https://..."

if not os.path.exists(INDEX_DIR):
    st.error(f"ì¸ë±ìŠ¤ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {INDEX_DIR}")
    st.stop()

# ì´ˆê¸°í™”
try:
    vs = get_vectorstore()
    st.write("âœ… index loaded")
    # ë¹ ë¥¸ í—¬ìŠ¤ì²´í¬(í•„í„° ì—†ì´)
    _probe = vs.as_retriever(search_type="mmr", search_kwargs={"k": 5}).get_relevant_documents(QUERY_PREFIX + "í—¬ìŠ¤ì²´í¬")
    st.write(f"ğŸ” retriever test docs = {len(_probe)}")
    llm = get_llm()
    st.write(f"âœ… chain OK")
except Exception:
    st.error("ì´ˆê¸°í™” ì˜¤ë¥˜")
    st.code(traceback.format_exc())
    st.stop()

question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ) SSG ìµœì • ì„ ìˆ˜ì˜ ë³„ëª…ì€?")
if question:
    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        name = extract_name(question)
        stats_intent = is_stats_query(question)

        route = "stats-only" if stats_intent else "wiki-biased"
        st.caption(f"ë¼ìš°íŒ…: **{route}** | ì¶”ì¶œ ì„ ìˆ˜: **{name or 'ì—†ìŒ'}**")

        filter_dict = {"player": name} if name else None

        # âœ… ë§¤ ì§ˆë¬¸ë§ˆë‹¤ fresh retriever ìƒì„± (í•„í„° ëˆ„ì  ë°©ì§€)
        retriever = make_retrievers(vs, filter_dict, stats_intent)

        prompt = get_prompt()
        doc_chain = create_stuff_documents_chain(llm, prompt)
        rag_chain = create_retrieval_chain(retriever, doc_chain)

        try:
            resp = rag_chain.invoke({"input": QUERY_PREFIX + question})
            st.subheader("ğŸ¤– AI ë‹µë³€")
            st.write(resp.get("answer", ""))

            with st.expander("RAG Context í™•ì¸í•˜ê¸°"):
                for i, d in enumerate(resp.get("context", []), 1):
                    st.markdown(f"**ë¬¸ì„œ #{i}**")
                    if d.metadata:
                        st.code(d.metadata, language="json")
                    preview = d.page_content if len(d.page_content) < 1200 else d.page_content[:1200] + "â€¦"
                    st.write(preview)
                    st.markdown("---")
        except Exception:
            st.error("ì§ˆì˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.code(traceback.format_exc())

